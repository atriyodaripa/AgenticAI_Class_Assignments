{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8fa1baee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.types import Command\n",
    "from langgraph.graph import MessagesState\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Annotated, Sequence, Optional, Dict, Any, TypedDict, Literal\n",
    "from langchain_core.messages import BaseMessage, AIMessage\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db034cd",
   "metadata": {},
   "source": [
    "### Initializing the LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "992e4d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Langchain and Langsmith tracing\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "\n",
    "## Getting Froq API key\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# EMBEDDING_MODEL = \"BAAI/bge-small-en\"\n",
    "GROQ_INFERENCE_MODEL = \"deepseek-r1-distill-llama-70b\"\n",
    "OPENAI_INFERENCE_MODEL = \"gpt-4o\"\n",
    "# INFERENCE_MODEL = \"gemma2-9b-it\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ac07e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------Creating the response from llm based on contexts--------\n"
     ]
    }
   ],
   "source": [
    "llm = ChatGroq(model=GROQ_INFERENCE_MODEL, temperature=0.3)\n",
    "print('--------Creating the response from llm based on contexts--------')\n",
    "\n",
    "# llm = ChatOpenAI(model=OPENAI_INFERENCE_MODEL, temperature=0.3)\n",
    "# print('--------Creating the response from llm based on contexts--------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387cac35",
   "metadata": {},
   "source": [
    "### State of the Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ea0385",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisorState(MessagesState):\n",
    "    \"\"\"State of the Supervisor Agent\"\"\"\n",
    "    query: str\n",
    "    research_results: Optional[Dict[str, Any]] = None\n",
    "    summary_results: Optional[Dict[str, Any]] = None\n",
    "    final_documents: Optional[str] = None\n",
    "    next: Optional[Literal['research', 'report', 'FINISH']] = None\n",
    "    reasoning: Optional[str] = None\n",
    "    task_details: Optional[str] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8e3aef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchState(BaseModel):\n",
    "    \"\"\"State of the Team 1: Research Agent\"\"\"\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    research_query: str\n",
    "    medical_results: Optional[Dict[str, Any]]\n",
    "    financial_results: Optional[Dict[str, Any]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef32beb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportingState(BaseModel):\n",
    "    \"\"\"State of the Team 2: Reporting Agent\"\"\"\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    research_data: Dict[str, Any]\n",
    "    summary: Optional[str]\n",
    "    final_report: Optional[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8595c21c",
   "metadata": {},
   "source": [
    "### Router of the Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d38c6a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisorRouter(TypedDict):\n",
    "    next: Literal['research', 'report', 'FINISH']\n",
    "    reasoning: str\n",
    "    task_details: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5cd6fdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchRouter(TypedDict):\n",
    "    next: Literal['medical', 'financial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "362161ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportRouter(TypedDict):\n",
    "    next: Literal['summary', 'document']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc068a6",
   "metadata": {},
   "source": [
    "### Agent Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eee303a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisor_prompt_template = \"\"\"You are the Supervisor Agent coordinating a hierarchical multi-agent research system.\n",
    "\n",
    "Your responsibilities:\n",
    "1. Analyze incoming requests to determine if research or reporting is needed\n",
    "2. Coordinate between Team 1 (Research) and Team 2 (Reporting)\n",
    "3. Make decisions on workflow progression\n",
    "\n",
    "Teams under your supervision:\n",
    "- Team 1 (Research): Coordinates medical/pharma (Team 3) and financial (Team 4) research\n",
    "- Team 2 (Reporting): Coordinates summary creation (Team 5) and document generation (Team 6)\n",
    "\n",
    "Decision criteria:\n",
    "- If no research results exist and task requires data gathering then route to \"research\" agent i.e. Team 1\n",
    "- If research results exist but no report generated then route to \"reporting\" agent i.e. Team 2  \n",
    "- If final document is complete then route to \"end\"\n",
    "\n",
    "Always respond with your decision and reasoning in JSON format:\n",
    "{{  \"next_action\": \"research|reporting|end\", \n",
    "    \"reasoning\": \"explanation\", \n",
    "    \"task_details\": \"specific instructions\"}}\n",
    "\n",
    "Here is the user query: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ff091f",
   "metadata": {},
   "source": [
    "### Agent Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c08c4f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisor_prompt = PromptTemplate(\n",
    "    template=supervisor_prompt_template,\n",
    "    input_variables=[\"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f17afbf",
   "metadata": {},
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343f3ea1",
   "metadata": {},
   "source": [
    "#### Supervisor Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271035ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervisor(state:SupervisorState)->Command[Literal['research', 'report', '__end__']]:\n",
    "    \"\"\"This is the supervisor agent. It takes the query and redirects it to either the research node or reporting node\"\"\"\n",
    "    llm_with_structured_output = llm.with_structured_output(SupervisorRouter)\n",
    "    formatted_prompt = supervisor_prompt_template.format(question=state[\"query\"])\n",
    "    response = llm_with_structured_output.invoke(formatted_prompt)\n",
    "    \n",
    "    goto = response[\"next\"]\n",
    "\n",
    "    if goto == \"FINISH\":\n",
    "        goto=END\n",
    "    \n",
    "    supervisor_message = AIMessage(\n",
    "        content=f\"SUPERVISOR DECISION: Routing to {goto}. Reasoning: {response['reasoning']}. Task Details: {response['task_details']}\"\n",
    "    )\n",
    "    \n",
    "    return Command(goto=goto, update={\n",
    "        \"query\": state.query,\n",
    "        \"next\": goto,\n",
    "        \"reasoning\": response[\"reasoning\"],\n",
    "        \"task_details\": response[\"task_details\"],\n",
    "        \"messages\": [supervisor_message]})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b6f1aa",
   "metadata": {},
   "source": [
    "#### Researcher Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c56fedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def researcher(state:AgentState):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77030bb5",
   "metadata": {},
   "source": [
    "#### Reporter Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00a07b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reporter(state:AgentState):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98063e52",
   "metadata": {},
   "source": [
    "#### Medical Researcher Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68dc2dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def medical_researcher(state:AgentState):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4e4c95",
   "metadata": {},
   "source": [
    "#### Finance Researcher Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0157afd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finance_researcher(state:AgentState):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72db7e0f",
   "metadata": {},
   "source": [
    "#### Document Summarizer Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e131de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_summarizer(state:AgentState):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77891b28",
   "metadata": {},
   "source": [
    "#### Document Generator Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb9b182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_generator(state:AgentState):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275b5fcf",
   "metadata": {},
   "source": [
    "### Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fc9bf9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x236a3262e90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder = StateGraph(AgentState)\n",
    "graph_builder.add_node(\"Researcher\", researcher)\n",
    "graph_builder.add_node(\"Reporter\", reporter)\n",
    "graph_builder.add_node(\"Supervisor\",supervisor)\n",
    "graph_builder.add_node(\"Medical Researcher\", medical_researcher)\n",
    "graph_builder.add_node(\"Finance Researcher\", finance_researcher)\n",
    "graph_builder.add_node(\"Document Summarizer\", document_summarizer)\n",
    "graph_builder.add_node(\"Document Generator\", document_generator)\n",
    "graph_builder.add_edge(START, \"Supervisor\")\n",
    "# graph_builder.add_conditional_edges(\"ai_assistant\",\n",
    "#                                     tools_condition)\n",
    "# graph_builder.add_edge(\"tools\",\"ai_assistant\")\n",
    "# app_react = graph_builder.compile(checkpointer=memory, interrupt_before=[\"tools\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
