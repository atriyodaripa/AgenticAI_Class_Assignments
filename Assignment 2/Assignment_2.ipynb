{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46ee280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_groq import ChatGroq\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import pprint\n",
    "import pdfplumber\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders.pdf import PyMuPDFLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from qdrant_client import QdrantClient as RawQdrantClient\n",
    "from qdrant_client.http import models\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "import uuid\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64edb01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Langchain and Langsmith tracing\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "\n",
    "## Getting Froq API key\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "## Getting qdrant vector db API key\n",
    "os.environ['QDRANT_API_KEY'] = os.getenv('QDRANT_API_KEY')\n",
    "os.environ['QDRANT_URL'] = os.getenv('QDRANT_URL')\n",
    "\n",
    "EMBEDDING_MODEL = \"all-MiniLM-L6-v2\"\n",
    "INFERENCE_MODEL = \"gemma2-9b-it\"\n",
    "HNSW_COLLECTION_NAME = \"hnsw_collection\"\n",
    "IVF_COLLECTION_NAME = \"ivf_collection\"\n",
    "FLAT_COLLECTION_NAME = \"flat_collection\"\n",
    "\n",
    "CONTENT_KEY = \"text_content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b91d78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"Generative AI with LangChain (2024).pdf\"\n",
    "image_folder = \"images\"\n",
    "os.makedirs(image_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0a509c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PATH'] += os.pathsep + r'C:\\\\Program Files\\\\Tesseract-OCR'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f052532",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511b5e30",
   "metadata": {},
   "source": [
    "### Function to extract texts, images and tables from pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d433ec05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_elements_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts texts, table contents and images from a PDF.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        documents = []\n",
    "        print(f\"Extracting text contents from '{os.path.basename(pdf_path)}'\")\n",
    "        # Extract text contents using pdfplumber\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page_num, page in enumerate(pdf.pages):\n",
    "                text = page.extract_text()\n",
    "                if text.strip():\n",
    "                    metadata = {\n",
    "                        \"source\": os.path.basename(pdf_path),\n",
    "                        \"page\": page_num + 1,\n",
    "                        \"type\": \"text\"\n",
    "                    }\n",
    "                    documents.append(Document(page_content=text, metadata=metadata))\n",
    "        \n",
    "        print(f\"Extracting table contents from '{os.path.basename(pdf_path)}'\")\n",
    "        # Extract table contents using pdfplumber\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page_num, page in enumerate(pdf.pages):\n",
    "                tables = page.extract_tables()\n",
    "                for table_num, table_data in enumerate(tables):\n",
    "                    if table_data: # Ensure table_data is not None or empty\n",
    "                        # Flatten table data into a string format\n",
    "                        table_content = \"\\n\".join([\"\\t\".join(map(str, row)) for row in table_data if row])\n",
    "                        if table_content.strip(): # Only add non-empty tables\n",
    "                            metadata = {\n",
    "                                \"source\": os.path.basename(pdf_path),\n",
    "                                \"page\": page_num + 1,\n",
    "                                \"table_num\": table_num + 1,\n",
    "                                \"type\": \"table\"\n",
    "                            }\n",
    "                            # Add a header to table content to distinguish it\n",
    "                            documents.append(Document(page_content=f\"Table {table_num+1} on page {page_num+1} contains:\\n{table_content}\", metadata=metadata))\n",
    "        \n",
    "        print(f\"Extracting images from '{os.path.basename(pdf_path)}'\")\n",
    "        # Extract images using pdfplumber\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page_num, page in enumerate(pdf.pages):\n",
    "                images = page.images\n",
    "                for image_num, image in enumerate(images):\n",
    "                    if image: # Ensure table_data is not None or empty\n",
    "                        bbox = [image['x0'], page.cropbox[3]-image['y1'],  image['x1'], page.cropbox[3]-image['y0']]\n",
    "                        img_page = page.crop(bbox=bbox)\n",
    "                        img_obj = img_page.to_image(resolution=500)\n",
    "                        # page_number = image['page_number']\n",
    "                        image_name_prefix = f'{page_num}-{image_num + 1}'\n",
    "                        image_name = f'{image_name_prefix}' + \".png\"\n",
    "                        image_path = f'{image_folder}\\\\{image_name}'\n",
    "                        img_obj.save(image_path)\n",
    "                        image_content = pytesseract.image_to_string(Image.open(image_path), lang='eng')\n",
    "                        metadata = {\n",
    "                                \"source\": os.path.basename(pdf_path),\n",
    "                                \"page\": page_num + 1,\n",
    "                                \"image_num\": image_num + 1,\n",
    "                                \"type\": \"image\",\n",
    "                                \"image_path\":image_path\n",
    "                            }\n",
    "                        # Add a header to table content to distinguish it\n",
    "                        documents.append(Document(page_content=f\"Image {image_num+1} on page {page_num+1} contains:\\n{image_content}\", metadata=metadata))\n",
    "        return documents\n",
    "    except Exception as e:\n",
    "            print(f\"Error extracting details from {pdf_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b33bcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text contents from 'Generative AI with LangChain (2024).pdf'\n",
      "Extracting table contents from 'Generative AI with LangChain (2024).pdf'\n",
      "Extracting images from 'Generative AI with LangChain (2024).pdf'\n"
     ]
    }
   ],
   "source": [
    "raw_docs = extract_elements_from_pdf(pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98a0549c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'Generative AI with LangChain (2024).pdf', 'page': 2, 'type': 'text'}, page_content='Generative AI with LangChain\\nBuild large language model (LLM) apps with Python,\\nChatGPT, and other LLMs\\nBen Auffarth\\nBIRMINGHAMâ€”MUMBAI')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63a8e5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\AgenticAI KrishNaikAcademy\\Classroom HandsOn\\agentic_class_venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embeddings=HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "text_splitter = SemanticChunker(embeddings, breakpoint_threshold_type='percentile', breakpoint_threshold_amount=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea967b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_splitter.split_documents([doc for doc in raw_docs if doc.metadata['type']=='text'])\n",
    "chunks.extend(doc for doc in raw_docs if doc.metadata['type']!='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ec7177a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "984"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03288d82",
   "metadata": {},
   "source": [
    "#### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "995855b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_docs(doc_chunks):\n",
    "    chunk_texts_for_embedding = [chunk.page_content for chunk in doc_chunks]\n",
    "    chunk_embeddings = embeddings.embed_documents(chunk_texts_for_embedding)\n",
    "    upload_data = []\n",
    "    for i, (chunk, vector) in enumerate(zip(doc_chunks, chunk_embeddings)):\n",
    "        current_chunk_metadata = {}\n",
    "        for k, v_meta in chunk.metadata.items():\n",
    "            current_chunk_metadata[k] = v_meta\n",
    "\n",
    "        payload_for_qdrant = {\n",
    "            CONTENT_KEY: chunk.page_content,\n",
    "            **current_chunk_metadata\n",
    "        }\n",
    "        # Generate a unique UUID for each point\n",
    "        unique_id = str(uuid.uuid4()) \n",
    "\n",
    "        upload_data.append(\n",
    "            models.PointStruct(\n",
    "                id=unique_id, \n",
    "                payload=payload_for_qdrant,\n",
    "                vector=vector\n",
    "            )\n",
    "        )\n",
    "    return upload_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1a73005",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_upload = embed_docs(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1488c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk_texts_for_embedding = [chunk.page_content for chunk in chunks]\n",
    "# chunk_embeddings = embeddings.embed_documents(chunk_texts_for_embedding)\n",
    "# #store the main text content within the Qdrant payload\n",
    "# CONTENT_KEY_IN_PAYLOAD = \"text_content_for_langchain\"\n",
    "\n",
    "# points_to_upsert = []\n",
    "# for i, (chunk, vector) in enumerate(zip(chunks, chunk_embeddings)):\n",
    "#     current_chunk_metadata = {}\n",
    "#     for k, v_meta in chunk.metadata.items():\n",
    "#         current_chunk_metadata[k] = v_meta\n",
    "\n",
    "#     payload_for_qdrant = {\n",
    "#         CONTENT_KEY_IN_PAYLOAD: chunk.page_content,\n",
    "#         **current_chunk_metadata\n",
    "#     }\n",
    "#     # Generate a unique UUID for each point\n",
    "#     unique_id = str(uuid.uuid4()) \n",
    "\n",
    "#     points_to_upsert.append(\n",
    "#         models.PointStruct(\n",
    "#             id=unique_id, \n",
    "#             payload=payload_for_qdrant,\n",
    "#             vector=vector\n",
    "#         )\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3de61a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# points_to_upsert[0].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "48e48550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pprint\n",
    "# sample_payload = {}\n",
    "# for k, v in points_to_upsert[0].payload.items():\n",
    "#     if isinstance(v, str) and len(v) > 50:\n",
    "#         sample_payload[k] = v[:50] + '...'\n",
    "#     else:\n",
    "#         sample_payload[k] = v\n",
    "\n",
    "# pprint.pprint(sample_payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dddd13",
   "metadata": {},
   "source": [
    "#### QDRANT Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6c80d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qdrant:\n",
    "    def __init__(self, url=os.environ['QDRANT_URL'], api_key=os.environ['QDRANT_API_KEY'], timeout=60):\n",
    "        self.url = url\n",
    "        self.api_key = api_key\n",
    "        self.timeout = timeout\n",
    "    \n",
    "    def create_connnection(self):\n",
    "        try:\n",
    "            self.qdrant_client = RawQdrantClient(\n",
    "                url=self.url,\n",
    "                api_key=self.api_key,\n",
    "                timeout=self.timeout # Increased timeout for potentially long operations\n",
    "            )\n",
    "            print(\"Connection successful.\")\n",
    "            return self.qdrant_client\n",
    "        except Exception as e:\n",
    "            self.qdrant_client = None # Set to None if fails\n",
    "            raise Exception (f\"Error connecting to Qdrant: {e}\")\n",
    "    \n",
    "    def get_collection(self):\n",
    "        try:\n",
    "            self.collections = self.qdrant_client.get_collections()\n",
    "            return self.collections\n",
    "        except Exception as e:\n",
    "            raise Exception (f\"Error connecting to Qdrant: {e}\")\n",
    "    \n",
    "    def create_collections(self, collection_name, index_type=\"flat\"):\n",
    "        existing_collections = []\n",
    "        try:\n",
    "            collections_response = self.get_collection()\n",
    "            self.existing_collections = [c.name for c in collections_response.collections]\n",
    "            if collection_name in existing_collections:\n",
    "                print(f\"  Collection '{collection_name}' already exists. No action needed.\")\n",
    "            else:\n",
    "                if index_type == \"flat\":\n",
    "                    self.qdrant_client.create_collection(\n",
    "                        collection_name=collection_name,\n",
    "                        vectors_config=models.VectorParams(size=384, distance=models.Distance.COSINE)\n",
    "                    )\n",
    "                    self.existing_collections.append(collection_name)\n",
    "                elif index_type == \"hnsw\":\n",
    "                    self.qdrant_client.create_collection(\n",
    "                        collection_name=collection_name,\n",
    "                        vectors_config=models.VectorParams(size=384, distance=models.Distance.COSINE),\n",
    "                        hnsw_config={\n",
    "                            \"m\": 16,  # number of connections per layer\n",
    "                            \"ef_construct\": 100,  # size of the dynamic candidate list\n",
    "                            \"full_scan_threshold\": 10000  # threshold for switching to brute force search\n",
    "                        }\n",
    "                    )\n",
    "                    self.existing_collections.append(collection_name)\n",
    "            return self.existing_collections\n",
    "        except Exception as e:\n",
    "                raise Exception (f\"Error connecting to Qdrant: {e}\")\n",
    "    \n",
    "    def upsert_embeddings(self, embeddings_list):\n",
    "        BATCH_SIZE = 100\n",
    "        for collection_name in self.existing_collections:\n",
    "            for i in range(0, len(embeddings_list), BATCH_SIZE):\n",
    "                batch_of_points = embeddings_list[i : i + BATCH_SIZE]\n",
    "                try:\n",
    "                    self.qdrant_client.upsert(\n",
    "                        collection_name=collection_name,\n",
    "                        points=batch_of_points,\n",
    "                        wait=True # Wait for the batch to complete\n",
    "                    )\n",
    "                    count_result = self.qdrant_client.count(collection_name=collection_name, exact=True)\n",
    "                    print(f\"{count_result} is currently present in collection {collection_name}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error upserting data into '{collection_name}': {e}\")\n",
    "                    continue\n",
    "\n",
    "    def search_vectors(self, collection_name, query_vector, top_results):\n",
    "        search_result_points = self.qdrant_client.search(\n",
    "            collection_name=collection_name,\n",
    "            query_vector=query_vector,\n",
    "            limit=top_results,\n",
    "            with_payload=True,\n",
    "            with_vectors=False\n",
    "        )\n",
    "        manually_created_docs = []\n",
    "        if search_result_points:\n",
    "            for i, point in enumerate(search_result_points):\n",
    "                if point.payload and CONTENT_KEY in point.payload:\n",
    "                    doc_content = point.payload[CONTENT_KEY]\n",
    "                    doc_metadata = {k: v for k, v in point.payload.items() if k != CONTENT_KEY}\n",
    "                    doc_metadata[\"score\"] = point.score\n",
    "                    manually_created_docs.append(\n",
    "                        Document(page_content=doc_content, metadata=doc_metadata)\n",
    "                    )\n",
    "        return manually_created_docs\n",
    "                \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b44afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# qdrant_client = RawQdrantClient(\n",
    "#                 url=os.environ['QDRANT_URL'],\n",
    "#                 api_key=os.environ['QDRANT_API_KEY'],\n",
    "#                 timeout=60 # Increased timeout for potentially long operations\n",
    "#             )\n",
    "# qdrant_client.delete_collection(collection_name=\"hnsw_collection\")\n",
    "# qdrant_client.delete_collection(collection_name=\"flat_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa11326b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['flat_collection', 'hnsw_collection']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qdrant = Qdrant()\n",
    "qdrant.create_connnection()\n",
    "qdrant.create_collections(FLAT_COLLECTION_NAME)\n",
    "qdrant.create_collections(HNSW_COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0d12461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count=100 is currently present in collection flat_collection\n",
      "count=200 is currently present in collection flat_collection\n",
      "count=300 is currently present in collection flat_collection\n",
      "count=400 is currently present in collection flat_collection\n",
      "count=500 is currently present in collection flat_collection\n",
      "count=600 is currently present in collection flat_collection\n",
      "count=700 is currently present in collection flat_collection\n",
      "count=800 is currently present in collection flat_collection\n",
      "count=900 is currently present in collection flat_collection\n",
      "count=984 is currently present in collection flat_collection\n",
      "count=100 is currently present in collection hnsw_collection\n",
      "count=200 is currently present in collection hnsw_collection\n",
      "count=300 is currently present in collection hnsw_collection\n",
      "count=400 is currently present in collection hnsw_collection\n",
      "count=500 is currently present in collection hnsw_collection\n",
      "count=600 is currently present in collection hnsw_collection\n",
      "count=700 is currently present in collection hnsw_collection\n",
      "count=800 is currently present in collection hnsw_collection\n",
      "count=900 is currently present in collection hnsw_collection\n",
      "count=984 is currently present in collection hnsw_collection\n"
     ]
    }
   ],
   "source": [
    "qdrant.upsert_embeddings(data_to_upload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48f648f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qdrant_client.create_collection(\n",
    "#     collection_name=HNSW_COLLECTION_NAME,\n",
    "#     vectors_config=models.VectorParams(size=384, distance=models.Distance.COSINE),\n",
    "#     hnsw_config={\n",
    "#             \"m\": 16,  # number of connections per layer\n",
    "#             \"ef_construct\": 100,  # size of the dynamic candidate list\n",
    "#             \"full_scan_threshold\": 10000  # threshold for switching to brute force search\n",
    "#         }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50cb03c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qdrant_client.create_collection(\n",
    "#     collection_name=FLAT_COLLECTION_NAME,\n",
    "#     vectors_config=models.VectorParams(size=384, distance=models.Distance.COSINE)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d17595a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collections_response = qdrant_client.get_collections()\n",
    "# collections_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7717bdc5",
   "metadata": {},
   "source": [
    "### Retriever Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "344edb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def retrieve_documents(query, collection_name, embeddings_model, index_type, top_results):\n",
    "    print('Retrieving Documents initially from the Vector Database.....')\n",
    "    retrieval_times = {}\n",
    "    query_vector = embeddings_model.embed_query(query)\n",
    "    start_time = time.time()\n",
    "    retrieved_docs = qdrant.search_vectors(collection_name, query_vector, top_results)\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    retrieval_times[index_type] = duration\n",
    "    print(f\"  Retrieved {len(retrieved_docs)} documents in {duration:.4f} seconds.\")\n",
    "    return retrieved_docs, duration\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "bf5b6180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"How to build an application for customer service?\"\n",
    "\n",
    "# retrieved_docs_flat, retrieval_time_flat = retrieve_documents(query, 'flat_collection', embeddings, 'flat', 3)\n",
    "# retrieved_docs_hnsw, retrieval_time_hnsw = retrieve_documents(query, 'hnsw_collection', embeddings, 'hnsw', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "eaa1bfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieved_docs_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "074c7400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieved_docs_hnsw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eaa6bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [doc.page_content for doc in retrieved_docs_hnsw]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd102dd",
   "metadata": {},
   "source": [
    "### Re-Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e334f103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_rank_retrieved_docs(query, collection, index_type, top_reranked_retrievals=5):\n",
    "    print('Re Ranking the Retrieved Documents using CrossEncoder')\n",
    "    reranker_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "    docs_without_reranking, retrieval_time = retrieve_documents(\n",
    "        query=query,\n",
    "        collection_name=collection,\n",
    "        embeddings_model=embeddings,\n",
    "        index_type=index_type,\n",
    "        top_results=10\n",
    "    )\n",
    "    if docs_without_reranking:\n",
    "        sentence_pairs = [[query, doc.page_content] for doc in docs_without_reranking]\n",
    "        rerank_scores = reranker_model.predict(sentence_pairs)\n",
    "\n",
    "        # Combine documents with their rerank scores\n",
    "        docs_with_rerank_scores = list(zip(docs_without_reranking, rerank_scores))\n",
    "\n",
    "        # Sort the documents by rerank score in descending order\n",
    "        reranked_docs_with_scores = sorted(docs_with_rerank_scores, key=lambda item: item[1], reverse=True)\n",
    "        reranked_docs = [doc[0] for doc in reranked_docs_with_scores]\n",
    "\n",
    "        print(\"Reranked Documents (Top 5):\")\n",
    "        for i, (doc, score) in enumerate(reranked_docs_with_scores[:top_reranked_retrievals]): # Print top 5 reranked results\n",
    "            print(f\"{i+1}. Rerank Score: {score:.4f}, Vector Score: {doc.metadata['score']:.4f}, Page: {doc.metadata['page']}, Source: {doc.metadata['source']}\")\n",
    "        \n",
    "        return reranked_docs[:top_reranked_retrievals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8ddd9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reranked_output = re_rank_retrieved_docs(query, 'hnsw_collection', 'hnsw')\n",
    "# print(\"^^^^^^^^^^^^^^^^^^^^^^^^^^^\")\n",
    "# print(reranked_output)\n",
    "# print(\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
    "# # print([doc[0].page_content for doc in reranked_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc78b6d",
   "metadata": {},
   "source": [
    "### RAG CHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02c8c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(query,reranked_docs):\n",
    "    prompt_template = PromptTemplate(\n",
    "    input_variables=[\"query\", \"context\"],\n",
    "    template=\"\"\"\n",
    "    You are an expert AI assistant. Answer the following question based on the provided context.\n",
    "\n",
    "    Question: {query}\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "\n",
    "    Instructions:\n",
    "    1. Provide a clear, concise answer.\n",
    "    2. If the context doesn't contain the answer, say \"I could not find an answer.\"\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    )\n",
    "    # Example: Format the prompt with retrieved docs\n",
    "    documents_str = \"\\n\\n\".join([f\"Document {i+1}:\\n{doc.page_content[:500]}...\" for i, doc in enumerate(reranked_docs)])\n",
    "\n",
    "    prompt = prompt_template.format(\n",
    "    query=query,\n",
    "    context=documents_str\n",
    "    )\n",
    "    print(\"===== GENERATED PROMPT =====\")\n",
    "    return prompt\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e0ee0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pprint\n",
    "# pprint.pprint(create_prompt(\"What is Fake LLM?\",reranked_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c190a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rag_chain(query, collection, index_type):\n",
    "    # 1. Document Retrieval and Reranking\n",
    "    reranked_retrieved_docs = re_rank_retrieved_docs(\n",
    "        query=query,\n",
    "        collection=collection,\n",
    "        index_type=index_type,\n",
    "        top_reranked_retrievals=5\n",
    "    )\n",
    "\n",
    "    prompt = create_prompt(query, reranked_retrieved_docs)\n",
    "\n",
    "    # print(\"***********************************************\")\n",
    "\n",
    "    # print(f\"Prompt: {prompt}\")\n",
    "\n",
    "    # print(\"***********************************************\")\n",
    "    llm = ChatGroq(model=INFERENCE_MODEL, temperature=0.3)\n",
    "    llm_response_obj = llm.invoke(prompt)\n",
    "    return llm_response_obj.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "299a6131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re Ranking the Retrieved Documents using CrossEncoder\n",
      "Retrieving Documents initially from the Vector Database.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atriy\\AppData\\Local\\Temp\\ipykernel_16128\\320366456.py:74: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result_points = self.qdrant_client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Retrieved 10 documents in 0.8419 seconds.\n",
      "Reranked Documents (Top 5):\n",
      "1. Rerank Score: 5.7613, Vector Score: 0.5781, Page: 95, Source: Generative AI with LangChain (2024).pdf\n",
      "2. Rerank Score: -1.0813, Vector Score: 0.4570, Page: 123, Source: Generative AI with LangChain (2024).pdf\n",
      "3. Rerank Score: -1.7648, Vector Score: 0.4845, Page: 66, Source: Generative AI with LangChain (2024).pdf\n",
      "4. Rerank Score: -2.1071, Vector Score: 0.4860, Page: 62, Source: Generative AI with LangChain (2024).pdf\n",
      "5. Rerank Score: -2.6208, Vector Score: 0.4486, Page: 150, Source: Generative AI with LangChain (2024).pdf\n",
      "===== GENERATED PROMPT =====\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Fake LLM is a tool from the langchain library that allows you to simulate the behavior of a real Large Language Model (LLM) without actually using one.  It's useful for testing and prototyping because it avoids rate limits and lets you specify predefined responses. \\n\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_rag_chain(\"What is Fake LLM?\", 'hnsw_collection', 'hnsw')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
